---
description: 
globs: 
alwaysApply: false
---
- xmem is a memory orchestrator for LLMs, combining long-term (vector DB) and short-term (context window/session) memory, with smarter RAG (retrieval-augmented generation) logic. This approach will maximize xmem’s value and future-proof it in the LLM ecosystem.
- Case we are using NextJS, always prefer TS instead of JS. Use JS only if the file requires. Feel free to use CJS or MJS when needed too.
- Always check for existing interfaces and types and constants, before creating new ones.
- Always try to decouple functions that might be reusable, constants and interfaces as well, centralizing them.
- Always use the d.ts format for the interfaces and types.
- Always try to use utility types.
- Always use pnpm to install packages.
- All the buttons and clickable items should have a style cursor-pointer.
- Never install things locally. Always prefer to use things on a docker.
- Case we need a LLM model, don't install local. Use it via API, in the lightest and free way.
- Always choose for the open source solutions.
- Always choose for the most common approach that top AI Engineers take.